{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad80f85",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "979fcee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.11-cp313-cp313-win_amd64.whl.metadata (5.1 kB)\n",
      "Downloading psycopg2_binary-2.9.11-cp313-cp313-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.7 MB 272.9 kB/s eta 0:00:09\n",
      "   ------- -------------------------------- 0.5/2.7 MB 272.9 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 332.3 kB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 332.3 kB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 332.3 kB/s eta 0:00:06\n",
      "   --------------- ------------------------ 1.0/2.7 MB 373.9 kB/s eta 0:00:05\n",
      "   --------------- ------------------------ 1.0/2.7 MB 373.9 kB/s eta 0:00:05\n",
      "   --------------- ------------------------ 1.0/2.7 MB 373.9 kB/s eta 0:00:05\n",
      "   --------------- ------------------------ 1.0/2.7 MB 373.9 kB/s eta 0:00:05\n",
      "   ------------------- -------------------- 1.3/2.7 MB 345.8 kB/s eta 0:00:05\n",
      "   ------------------- -------------------- 1.3/2.7 MB 345.8 kB/s eta 0:00:05\n",
      "   ------------------- -------------------- 1.3/2.7 MB 345.8 kB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 360.5 kB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 360.5 kB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 360.5 kB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 360.5 kB/s eta 0:00:04\n",
      "   --------------------------- ------------ 1.8/2.7 MB 353.8 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 1.8/2.7 MB 353.8 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 1.8/2.7 MB 353.8 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 1.8/2.7 MB 353.8 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 2.1/2.7 MB 342.1 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 2.1/2.7 MB 342.1 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 2.1/2.7 MB 342.1 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 2.1/2.7 MB 342.1 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 2.1/2.7 MB 342.1 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 2.4/2.7 MB 331.8 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 2.4/2.7 MB 331.8 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 2.4/2.7 MB 331.8 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 2.6/2.7 MB 335.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 338.3 kB/s  0:00:07\n",
      "Installing collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.11\n",
      "Could not fetch URL https://pypi.org/simple/pip/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/pip/ (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1028)'))) - skipping\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbe1a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import psycopg2\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "45fc03c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kafka\n",
    "bootstrap_server = 'localhost:9092'\n",
    "topic = 'raw_sensor_data_ingestion'\n",
    "\n",
    "# Kafka consumer configuration\n",
    "consumer = KafkaConsumer(\n",
    "    topic,\n",
    "    bootstrap_servers=[bootstrap_server],\n",
    "    auto_offset_reset='earliest',\n",
    "    enable_auto_commit=True,\n",
    "    # group_id='my-group',\n",
    "    value_deserializer=lambda m: json.loads(m.decode('utf-8'))\n",
    ")\n",
    "\n",
    "# PostgreSQL connection config\n",
    "conn = psycopg2.connect(\n",
    "    dbname='iot_data_analytic',\n",
    "    user='admin',\n",
    "    password='admin',\n",
    "    host='localhost',\n",
    "    port='5432'\n",
    ")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aa2058",
   "metadata": {},
   "source": [
    "### DB Vehical details table CRUD operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98b14ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vehical_hourly_summary(data):\n",
    "    \"\"\"\n",
    "    data: dict with keys:\n",
    "      - sensor_id (str)\n",
    "      - avg_vehical_count_hourly (str)\n",
    "      - vehical_count_per_hour (numeric / float / int, optional, default 0)\n",
    "      - record_count (numeric / float / int, optional, default 0)\n",
    "    Returns: inserted row id or None on error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        insert_query = \"\"\"\n",
    "            INSERT INTO public.vehical_hourly_summary\n",
    "                (sensor_id,\n",
    "                 avg_vehical_count_hourly,\n",
    "                 vehical_count_per_hour,\n",
    "                 record_count, hour)\n",
    "            VALUES\n",
    "                (%(sensor_id)s,\n",
    "                 %(avg_vehical_count_hourly)s,\n",
    "                 %(vehical_count_per_hour)s,\n",
    "                 %(record_count)s, %(hour)s)\n",
    "            RETURNING id;\n",
    "        \"\"\"\n",
    "\n",
    "        mapping = {\n",
    "            \"sensor_id\": data[\"sensor_id\"],\n",
    "            \"avg_vehical_count_hourly\": data[\"avg_vehical_count_hourly\"],\n",
    "            \"vehical_count_per_hour\": data.get(\"vehical_count_per_hour\", 0),\n",
    "            \"record_count\": data.get(\"record_count\", 0),\n",
    "            \"hour\": data.get(\"hour\", -1)\n",
    "        }\n",
    "\n",
    "        cursor.execute(insert_query, mapping)\n",
    "        new_id = cursor.fetchone()[0]\n",
    "        conn.commit()\n",
    "        print(f\"Inserted vehical_hourly_summary id={new_id}\")\n",
    "        return new_id\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"Error inserting vehical_hourly_summary: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def get_vehical_hourly_summary_by_id(record_id):\n",
    "    \"\"\"\n",
    "    Returns a dict for the given id, or None if not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "            SELECT\n",
    "                id,\n",
    "                sensor_id,\n",
    "                avg_vehical_count_hourly,\n",
    "                created_date,\n",
    "                updated_at,\n",
    "                vehical_count_per_hour,\n",
    "                record_count,\n",
    "                hour\n",
    "            FROM public.vehical_hourly_summary\n",
    "            WHERE id = %s;\n",
    "        \"\"\"\n",
    "\n",
    "        cursor.execute(query, (record_id,))\n",
    "        row = cursor.fetchone()\n",
    "\n",
    "        if not row:\n",
    "            print(f\"No vehical_hourly_summary found with id={record_id}\")\n",
    "            return None\n",
    "\n",
    "        col_names = [desc[0] for desc in cursor.description]\n",
    "        result = dict(zip(col_names, row))\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving vehical_hourly_summary id={record_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def get_vehical_hourly_summaries(sensor_id=None):\n",
    "    \"\"\"\n",
    "    Returns a list of dicts.\n",
    "    If sensor_id is given, only records for that sensor are returned.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        base_query = \"\"\"\n",
    "            SELECT\n",
    "                id,\n",
    "                sensor_id,\n",
    "                avg_vehical_count_hourly,\n",
    "                created_date,\n",
    "                updated_at,\n",
    "                vehical_count_per_hour,\n",
    "                record_count,\n",
    "                hour\n",
    "            FROM public.vehical_hourly_summary\n",
    "        \"\"\"\n",
    "\n",
    "        if sensor_id is not None:\n",
    "            query = base_query + \" WHERE sensor_id = %s ORDER BY created_date DESC;\"\n",
    "            params = (sensor_id,)\n",
    "        else:\n",
    "            query = base_query + \" ORDER BY created_date DESC;\"\n",
    "            params = None\n",
    "\n",
    "        cursor.execute(query, params)\n",
    "        rows = cursor.fetchall()\n",
    "\n",
    "        col_names = [desc[0] for desc in cursor.description]\n",
    "        results = [dict(zip(col_names, row)) for row in rows]\n",
    "\n",
    "        print(f\"Retrieved {len(results)} vehical_hourly_summary record(s)\")\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving vehical_hourly_summary records: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def update_vehical_hourly_summary(record_id, data):\n",
    "    \"\"\"\n",
    "    data: dict with any of:\n",
    "      - sensor_id\n",
    "      - avg_vehical_count_hourly\n",
    "      - vehical_count_per_hour\n",
    "      - record_count\n",
    "      - hour\n",
    "    Only provided fields will be updated.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Build dynamic SET clause\n",
    "        fields = []\n",
    "        params = {}\n",
    "\n",
    "        if \"sensor_id\" in data:\n",
    "            fields.append(\"sensor_id = %(sensor_id)s\")\n",
    "            params[\"sensor_id\"] = data[\"sensor_id\"]\n",
    "\n",
    "        if \"avg_vehical_count_hourly\" in data:\n",
    "            fields.append(\"avg_vehical_count_hourly = %(avg_vehical_count_hourly)s\")\n",
    "            params[\"avg_vehical_count_hourly\"] = data[\"avg_vehical_count_hourly\"]\n",
    "\n",
    "        if \"vehical_count_per_hour\" in data:\n",
    "            fields.append(\"vehical_count_per_hour = %(vehical_count_per_hour)s\")\n",
    "            params[\"vehical_count_per_hour\"] = data[\"vehical_count_per_hour\"]\n",
    "\n",
    "        if \"record_count\" in data:\n",
    "            fields.append(\"record_count = %(record_count)s\")\n",
    "            params[\"record_count\"] = data[\"record_count\"]\n",
    "\n",
    "        if \"hour\" in data:\n",
    "            fields.append(\"hour = %(hour)s\")\n",
    "            params[\"hour\"] = data[\"hour\"]\n",
    "\n",
    "        if not fields:\n",
    "            print(\"No fields to update.\")\n",
    "            return False\n",
    "\n",
    "        # Always update updated_at\n",
    "        fields.append(\"updated_at = CURRENT_TIMESTAMP\")\n",
    "\n",
    "        update_query = f\"\"\"\n",
    "            UPDATE public.vehical_hourly_summary\n",
    "            SET {', '.join(fields)}\n",
    "            WHERE id = %(id)s;\n",
    "        \"\"\"\n",
    "\n",
    "        params[\"id\"] = record_id\n",
    "\n",
    "        cursor.execute(update_query, params)\n",
    "        conn.commit()\n",
    "\n",
    "        if cursor.rowcount == 0:\n",
    "            print(f\"No vehical_hourly_summary updated, id={record_id} not found.\")\n",
    "            return False\n",
    "\n",
    "        print(f\"Updated vehical_hourly_summary id={record_id}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"Error updating vehical_hourly_summary id={record_id}: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def delete_vehical_hourly_summary(record_id):\n",
    "    \"\"\"\n",
    "    Delete a record by id.\n",
    "    Returns True if a row was deleted, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        delete_query = \"\"\"\n",
    "            DELETE FROM public.vehical_hourly_summary\n",
    "            WHERE id = %s;\n",
    "        \"\"\"\n",
    "\n",
    "        cursor.execute(delete_query, (record_id,))\n",
    "        conn.commit()\n",
    "\n",
    "        if cursor.rowcount == 0:\n",
    "            print(f\"No vehical_hourly_summary deleted, id={record_id} not found.\")\n",
    "            return False\n",
    "\n",
    "        print(f\"Deleted vehical_hourly_summary id={record_id}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"Error deleting vehical_hourly_summary id={record_id}: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f9d319",
   "metadata": {},
   "source": [
    "##### Usage details# Create\n",
    "new_id = create_vehical_hourly_summary({\n",
    "    \"sensor_id\": \"CAM-00123\",\n",
    "    \"avg_vehical_count_hourly\": \"145.3\",\n",
    "    \"vehical_count_per_hour\": 160,\n",
    "    \"record_count\": 12,\n",
    "})\n",
    "\n",
    "##### Read one\n",
    "row = get_vehical_hourly_summary_by_id(new_id)\n",
    "\n",
    "##### Update\n",
    "update_vehical_hourly_summary(new_id, {\n",
    "    \"avg_vehical_count_hourly\": \"150.0\",\n",
    "    \"vehical_count_per_hour\": 170,\n",
    "})\n",
    "\n",
    "##### Delete\n",
    "delete_vehical_hourly_summary(new_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083c1657",
   "metadata": {},
   "source": [
    "### Logic calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "33ab8e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hourly_details(data, existing_records, mapping):\n",
    "\n",
    "    # Update the record count by one\n",
    "    record_count = existing_records[\"record_count\"] + 1  # including the new record\n",
    "    mapping[\"record_count\"] = record_count\n",
    "\n",
    "    # Calculate total vehical count\n",
    "    total_vehical_count = data[\"volume\"] + existing_records[\"vehical_count_per_hour\"]\n",
    "    mapping[\"vehical_count_per_hour\"] = total_vehical_count\n",
    "\n",
    "    # Calculate avg vehical count per sensor_id\n",
    "    avg_vehical_count_hourly = total_vehical_count / record_count\n",
    "    mapping[\"avg_vehical_count_hourly\"] = avg_vehical_count_hourly \n",
    "\n",
    "    return mapping\n",
    "\n",
    "def daily_peak_volume(data, existing_records, mapping):\n",
    "    return\n",
    "\n",
    "def daily_sensor_availability(data, existing_records, mapping):\n",
    "    return\n",
    "\n",
    "def update_details(data):\n",
    "\n",
    "    # Map the record fields into mapping object\n",
    "    mapping = {\n",
    "        \"sensor_id\": data[\"atd_device_id\"],\n",
    "        \"avg_vehical_count_hourly\": 0, # will be calculated in step 02\n",
    "        \"vehical_count_per_hour\": data.get(\"volume\", 0), # default to 0 if not present, for already exist records, add this amount to the existing value\n",
    "        \"record_count\": 0,  # will be calculated in step 01\n",
    "        \"hour\": data.get(\"hour\", -1)  # default to -1 if not present\n",
    "    }\n",
    "\n",
    "    # Check if a record exists for this sensor_id\n",
    "    existing_records = get_vehical_hourly_summaries(sensor_id=mapping[\"sensor_id\"])\n",
    "    if existing_records:\n",
    "\n",
    "        # Calculate Hourly Vehical Details\n",
    "        mapping = calculate_hourly_details(data, existing_records[0], mapping)\n",
    "\n",
    "        # Calculate daily peak volume across all sensors\n",
    "\n",
    "        # Calculate daily sensor availability percentage(%)\n",
    "\n",
    "\n",
    "        # Calculate daily traffic volume across all sensors\n",
    "        # mapping[\"avg_vehical_count_hourly\"] = total_vehical_count / total_records if total_records > 0 else 0\n",
    "\n",
    "        # Daily sensor availability percentage\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        # Update the most recent record\n",
    "        latest_record = existing_records[0]\n",
    "        update_vehical_hourly_summary(latest_record[\"id\"], mapping)\n",
    "        \n",
    "    else:\n",
    "\n",
    "        # 1. Update the record count by one\n",
    "        mapping[\"record_count\"] = 1  # including the new record\n",
    "\n",
    "        # 2. calculate avg vehical count per sensor_id\n",
    "        avg_vehical_count_hourly = data[\"volume\"] / 1  # record count taken as 1 since the first record\n",
    "        mapping[\"avg_vehical_count_hourly\"]\n",
    "        total_records = len(existing_records)\n",
    "\n",
    "        # Insert a new record\n",
    "        create_vehical_hourly_summary(mapping)  \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bddedbc",
   "metadata": {},
   "source": [
    "### Consume messages and insert into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a2ac5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 1 vehical_hourly_summary record(s)\n",
      "Updated vehical_hourly_summary id=3419\n",
      "Stopped consuming.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for message in consumer:\n",
    "        data = message.value  # This is a dict after JSON deserialization\n",
    "\n",
    "        # Insert/update data into PG table\n",
    "        update_details(data)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('Stopped consuming.')\n",
    "\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    consumer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
